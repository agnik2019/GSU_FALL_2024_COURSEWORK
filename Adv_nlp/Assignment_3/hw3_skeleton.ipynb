{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a78a98b",
   "metadata": {},
   "source": [
    "## Read the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64427ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import regex as re\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bbbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"wiki_articles_hw1_extended.db\")\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * from wiki_articles_hw1_extended\", con)\n",
    "con.close()\n",
    "#df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c6f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_words(df, field):\n",
    "    return [w.lower() for words in df[field] for w in re.split(r'\\||\\#', words) if len(w)>1 and w.lower() not in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5214abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = Counter(single_words(df, \"nouns\"))\n",
    "    \n",
    "voc = [w[0] for w in nouns.most_common(7000)]\n",
    "#voc.index(\"information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d146cc30",
   "metadata": {},
   "source": [
    "### Tasks 1a and 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aca742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'text', 'name', 'url', 'datePublished', 'dateModified',\n",
      "       'headline', 'nouns', 'adjectives', 'verbs', 'lemmas', 'nav', 'entities',\n",
      "       'noun_chunks', 'no_tokens', 'no_sentences', 'no_noun_chunks'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0fdf9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a35a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(voc) == 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615b5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(nouns[voc[-1]] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be426ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  title                                               text  \\\n",
      "0            Abuse case  From Wikipedia, the free encyclopedia\\n\\n\\nAbu...   \n",
      "1   Access-control list  From Wikipedia, the free encyclopedia\\n\\n\\nLis...   \n",
      "2    Antivirus software  From Wikipedia, the free encyclopedia\\n\\n\\nCom...   \n",
      "3  Application security  From Wikipedia, the free encyclopedia\\n\\n\\nMea...   \n",
      "4  Application firewall  From Wikipedia, the free encyclopedia\\n\\n\\nLay...   \n",
      "\n",
      "                   name                                                url  \\\n",
      "0            Abuse case           https://en.wikipedia.org/wiki/Abuse_case   \n",
      "1   Access-control list  https://en.wikipedia.org/wiki/Access-control_list   \n",
      "2    Antivirus software   https://en.wikipedia.org/wiki/Antivirus_software   \n",
      "3  Application security  https://en.wikipedia.org/wiki/Application_secu...   \n",
      "4  Application firewall  https://en.wikipedia.org/wiki/Application_fire...   \n",
      "\n",
      "          datePublished          dateModified  \\\n",
      "0  2010-03-19T13:30:06Z  2021-10-30T20:20:23Z   \n",
      "1  2002-07-12T08:06:50Z  2024-08-11T10:37:11Z   \n",
      "2  2003-07-16T00:29:07Z  2024-09-05T15:59:54Z   \n",
      "3  2005-08-29T21:54:46Z  2024-09-04T21:24:46Z   \n",
      "4  2004-09-04T01:27:44Z  2024-04-29T22:37:28Z   \n",
      "\n",
      "                                            headline  \\\n",
      "0  specification model for security requirements ...   \n",
      "1  list associated with a computing system resour...   \n",
      "2  computer security software that is used to pre...   \n",
      "3  measures taken to improve the security of an a...   \n",
      "4  a form of firewall that controls input/output ...   \n",
      "\n",
      "                                               nouns  \\\n",
      "0  abuse|case|specification|model|security|requir...   \n",
      "1  list|permission|system|resource|computer|secur...   \n",
      "2  computer|software|computer|virus|antivirus#med...   \n",
      "3  measure|security|application|application|secur...   \n",
      "4  Layer|application|layer|network|security|syste...   \n",
      "\n",
      "                                          adjectives  \\\n",
      "0  complete|more|harmful#just|coherent#instead|ac...   \n",
      "1  as|well#typical#only#many|historical|first#usu...   \n",
      "2  malicious|here#antiviral#open|originally#also#...   \n",
      "3  short|secure#final|preferably#whole|as|well#sp...   \n",
      "4  primary#additional#reliable#unsourced#generall...   \n",
      "\n",
      "                                               verbs  \\\n",
      "0  be|use#be#be|introduce|work#define|be|be#can|d...   \n",
      "1  be|associate#specify|be|grant|be|allow|give#sp...   \n",
      "2  defend|redirect#see#base|be|develop#abbreviate...   \n",
      "3  take|improve|include|introduce#be|improve|find...   \n",
      "4  be#see#need#help|improve|add#may|be|challenge|...   \n",
      "\n",
      "                                              lemmas  \\\n",
      "0   |abuse|case|be|a|specification|model|for|secu...   \n",
      "1   |list|of|permission|for|a|system|resource|in|...   \n",
      "2   |computer|software|to|defend|against|maliciou...   \n",
      "3   |measure|take|to|improve|the|security|of|an|a...   \n",
      "4   |Layer|7|/|application|layer|network|security...   \n",
      "\n",
      "                                                 nav  \\\n",
      "0  abuse|case|be|specification|model|security|req...   \n",
      "1  list|permission|system|resource|computer|secur...   \n",
      "2  computer|software|defend|malicious|computer|vi...   \n",
      "3  measure|take|improve|security|application|appl...   \n",
      "4  Layer|application|layer|network|security|syste...   \n",
      "\n",
      "                                            entities  \\\n",
      "0  John McDermott|Chris Fox|1999|Computer Science...   \n",
      "1  ACL#Alice|Bob|Alice|Bob#CLASS(TSOAUTH#ACLs|fir...   \n",
      "2  ClamTk|ClamAV|Tomasz Kojm|2001#1971–1980|pre-a...   \n",
      "3  AppSec#Android Applications Web Application Se...   \n",
      "4  Firewall#Unsourced#JSTOR|February 2010#two#Gen...   \n",
      "\n",
      "                                         noun_chunks  no_tokens  no_sentences  \\\n",
      "0   Abuse case|a specification model|security req...      351.0          17.0   \n",
      "1   List|permissions|a system resource|computer s...     1163.0          51.0   \n",
      "2   Computer software|malicious computer viruses|...     6168.0         258.0   \n",
      "3   Measures|the security|an application Applicat...      963.0          47.0   \n",
      "4   Layer 7/application layer network security sy...     1115.0          46.0   \n",
      "\n",
      "   no_noun_chunks  \n",
      "0            71.0  \n",
      "1           247.0  \n",
      "2          1211.0  \n",
      "3           193.0  \n",
      "4           199.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e832f",
   "metadata": {},
   "source": [
    "# Co-occurrence analysis (main homework)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896e1fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurrence of 'information' and 'security': 1350\n",
      "Shape of co-occurrence matrix: (7000, 7000)\n",
      "Sample co-occurrence matrix values: [[6764 1066  906 ...    2    0    0]\n",
      " [1066 5116  644 ...    0    0    0]\n",
      " [ 906  644 4526 ...    2    0    2]\n",
      " ...\n",
      " [   2    0    2 ...    2    0    0]\n",
      " [   0    0    0 ...    0    2    2]\n",
      " [   0    0    2 ...    0    2    2]]\n"
     ]
    }
   ],
   "source": [
    "coocc_matrix = np.zeros((7000, 7000), dtype=int)\n",
    "\n",
    "window_size = 5\n",
    "\n",
    "# Extract all tokens (nouns) from the dataframe\n",
    "tokens = single_words(df, \"nouns\")\n",
    "\n",
    "# Process the tokens to fill the co-occurrence matrix\n",
    "for i in range(len(tokens)):\n",
    "    token_i = tokens[i]\n",
    "    if token_i in voc:\n",
    "        idx_i = voc.index(token_i)\n",
    "\n",
    "        # Define the window for co-occurrence\n",
    "        window_start = max(0, i - window_size)\n",
    "        window_end = min(len(tokens), i + window_size + 1)\n",
    "\n",
    "        for j in range(window_start, window_end):\n",
    "            token_j = tokens[j]\n",
    "            if token_j in voc:\n",
    "                idx_j = voc.index(token_j)\n",
    "\n",
    "                coocc_matrix[idx_i, idx_j] += 1\n",
    "                coocc_matrix[idx_j, idx_i] += 1\n",
    "\n",
    "# Example of checking the co-occurrence of 'information' and 'security'\n",
    "index_info = voc.index(\"information\")\n",
    "index_security = voc.index(\"security\")\n",
    "print(f\"Co-occurrence of 'information' and 'security': {coocc_matrix[index_info][index_security]}\")\n",
    "\n",
    "# Optional: Output the shape of the co-occurrence matrix and some matrix stats\n",
    "print(\"Shape of co-occurrence matrix:\", coocc_matrix.shape)\n",
    "print(\"Sample co-occurrence matrix values:\", coocc_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540796fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the co-occurrence matrix symmetric? True\n"
     ]
    }
   ],
   "source": [
    "def is_symmetric(matrix):\n",
    "    rows, cols = matrix.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(i, cols):\n",
    "            if matrix[i, j] != matrix[j, i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Check if the co-occurrence matrix is symmetric\n",
    "symmetric_check = is_symmetric(coocc_matrix)\n",
    "print(f\"Is the co-occurrence matrix symmetric? {symmetric_check}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e29e155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important tokens by PageRank:\n",
      "Token: security, PageRank score: 0.020240331159672404\n",
      "Token: system, PageRank score: 0.016933937561286475\n",
      "Token: software, PageRank score: 0.014369306488398249\n",
      "Token: computer, PageRank score: 0.010477543094239448\n",
      "Token: attack, PageRank score: 0.009802975267342983\n",
      "Token: user, PageRank score: 0.009101839919493532\n",
      "Token: information, PageRank score: 0.009030091902604247\n",
      "Token: application, PageRank score: 0.006579550848280298\n",
      "Token: code, PageRank score: 0.006312133826602271\n",
      "Token: datum, PageRank score: 0.006183375710124651\n"
     ]
    }
   ],
   "source": [
    "stochastic_matrix = coocc_matrix / (coocc_matrix.sum(axis=0, keepdims=True) + 0.001)\n",
    "\n",
    "def pagerank(M, num_iterations=100, d=0.85):\n",
    "    N = M.shape[1]\n",
    "    v = np.ones(N) / N  \n",
    "    for i in range(num_iterations):\n",
    "        v = (1 - d) / N + d * M.dot(v)\n",
    "    return v\n",
    "\n",
    "pagerank_values = pagerank(stochastic_matrix)\n",
    "\n",
    "top_10_indices = np.argsort(pagerank_values)[-10:][::-1]\n",
    "top_10_tokens = [(voc[i], pagerank_values[i]) for i in top_10_indices]\n",
    "\n",
    "# Output the top 10 most important tokens\n",
    "print(\"Top 10 most important tokens by PageRank:\")\n",
    "for token, score in top_10_tokens:\n",
    "    print(f\"Token: {token}, PageRank score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242c7145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Dice coefficient values from dice_matrix:\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "dice_matrix = np.copy(coocc_matrix)\n",
    "\n",
    "def dice_coefficient(coocc_matrix, i, j):\n",
    "    \"\"\"Computes the Dice coefficient for tokens i and j.\"\"\"\n",
    "    intersection = coocc_matrix[i, j]\n",
    "    sum_of_rows = coocc_matrix[i, i] + coocc_matrix[j, j]\n",
    "    if sum_of_rows == 0:\n",
    "        return 0 \n",
    "    return (2 * intersection) / sum_of_rows\n",
    "\n",
    "num_tokens = coocc_matrix.shape[0]\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    for j in range(num_tokens):\n",
    "        dice_matrix[i, j] = dice_coefficient(coocc_matrix, i, j)\n",
    "\n",
    "# Output a few example values from the updated dice_matrix\n",
    "print(\"Sample Dice coefficient values from dice_matrix:\")\n",
    "print(dice_matrix[:5, :5])  # Print a 5x5 sample from the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30d73dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice coefficient ('software', 'security'): 0.16049601417183348\n",
      "Dice coefficient ('security', 'software'): 0.16049601417183348\n",
      "The Dice coefficients for both ('software', 'security') and ('security', 'software') match.\n"
     ]
    }
   ],
   "source": [
    "idx_software = voc.index(\"software\")\n",
    "idx_security = voc.index(\"security\")\n",
    "\n",
    "dice_software_security = dice_coefficient(coocc_matrix, idx_software, idx_security)\n",
    "dice_security_software = dice_coefficient(coocc_matrix, idx_security, idx_software)\n",
    "\n",
    "print(f\"Dice coefficient ('software', 'security'): {dice_software_security}\")\n",
    "print(f\"Dice coefficient ('security', 'software'): {dice_security_software}\")\n",
    "\n",
    "if dice_software_security == dice_security_software:\n",
    "    print(\"The Dice coefficients for both ('software', 'security') and ('security', 'software') match.\")\n",
    "else:\n",
    "    print(\"The Dice coefficients for ('software', 'security') and ('security', 'software') do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae63ebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (sklearn) between 'software' and 'security': 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "software_vector = dice_matrix[idx_software].reshape(1, -1)  # Reshape to 2D array for sklearn\n",
    "security_vector = dice_matrix[idx_security].reshape(1, -1)\n",
    "\n",
    "# Step 3: Calculate cosine similarity using sklearn's function\n",
    "cosine_sim_sklearn = cosine_similarity(software_vector, security_vector)[0][0]\n",
    "\n",
    "# Output the result\n",
    "print(f\"Cosine similarity (sklearn) between 'software' and 'security': {cosine_sim_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1178d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity (NumPy) between 'software' and 'security': 0.0\n"
     ]
    }
   ],
   "source": [
    "software_vector = dice_matrix[idx_software]\n",
    "security_vector = dice_matrix[idx_security]\n",
    "def cosine_similarity_np(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "cosine_sim_np = cosine_similarity_np(software_vector, security_vector)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Cosine similarity (NumPy) between 'software' and 'security': {cosine_sim_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed2112",
   "metadata": {},
   "source": [
    "The key observation is that **cosine similarity** between the context vectors of \"software\" and \"security\" is `0`, while the **Dice coefficient** is `0.16`. \n",
    "\n",
    "### Interpretation of the Results:\n",
    "\n",
    "1. **Cosine Similarity**:\n",
    "   - Cosine similarity measures the **angular distance** between two vectors. A value of `0` indicates that the context vectors of \"software\" and \"security\" are **orthogonal**, meaning there is no similarity or correlation in the directions of their context vectors. In other words, \"software\" and \"security\" do not tend to occur in the same context in the dataset based on their context vectors.\n",
    "\n",
    "2. **Dice Coefficient**:\n",
    "   - The Dice coefficient measures **pairwise overlap** between the occurrences of two terms. A value of `0.16` suggests that there is some degree of co-occurrence between \"software\" and \"security\", meaning they do appear together in certain contexts. The Dice coefficient focuses on the **raw frequency of co-occurrences** rather than the direction of the context vectors.\n",
    "\n",
    "### Conclusion:\n",
    "- The **cosine similarity** being `0` and the **Dice coefficient** being `0.16` shows that \"software\" and \"security\" may share some overlap in terms of co-occurrences, but their **context vectors** are different enough to be considered dissimilar in terms of their usage or context in the dataset. The Dice coefficient is influenced by the **frequency of co-occurrence**, whereas cosine similarity emphasizes the **relative direction** of the entire context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c07270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most similar tokens to 'software' by cosine similarity:\n",
      "Token: software, Cosine Similarity: 1.0\n",
      "Token: misnomer, Cosine Similarity: 0.0\n",
      "Token: net, Cosine Similarity: 0.0\n",
      "Token: tail, Cosine Similarity: 0.0\n",
      "Token: graduate, Cosine Similarity: 0.0\n",
      "Token: vbscript, Cosine Similarity: 0.0\n",
      "Token: lan, Cosine Similarity: 0.0\n",
      "Token: countermeasures, Cosine Similarity: 0.0\n",
      "Token: xerox, Cosine Similarity: 0.0\n",
      "Token: ethernet, Cosine Similarity: 0.0\n"
     ]
    }
   ],
   "source": [
    "software_vector = dice_matrix[idx_software].reshape(1, -1)\n",
    "\n",
    "cosine_similarities = cosine_similarity(dice_matrix, software_vector).flatten()\n",
    "\n",
    "top_10_indices = np.argsort(cosine_similarities)[-10:][::-1]\n",
    "\n",
    "print(\"Top 10 most similar tokens to 'software' by cosine similarity:\")\n",
    "for idx in top_10_indices:\n",
    "    print(f\"Token: {voc[idx]}, Cosine Similarity: {cosine_similarities[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f6ba8",
   "metadata": {},
   "source": [
    "### Step 1: My Prompt to ChatGPT\n",
    "**Prompt:**\n",
    "*\"Could you explain how Text-representing Centroids (TRC) can be implemented using static word embeddings? What conditions are necessary for this implementation? What are the advantages and disadvantages of using static embeddings for TRC, and in which application areas would this approach be most effective?\"*\n",
    "\n",
    "### Step 2: Version of ChatGPT Used\n",
    "I utilized **ChatGPT-4** to generate this response. GPT-4 is recognized for its detailed, coherent responses and strong explanations.\n",
    "\n",
    "### Step 3: ChatGPT’s Complete Answer\n",
    "**ChatGPT's Answer:**\n",
    "The **Text-representing Centroid (TRC)** approach can be realized using **static word embeddings**. Below is an explanation of the process, required conditions, benefits, limitations, and appropriate applications for this method.\n",
    "\n",
    "#### Implementing TRC Using Static Word Embeddings:\n",
    "A **centroid** refers to an average vector that summarizes a set of vectors. When applied to text, the goal is to derive a centroid vector representing an entire document by averaging the word embeddings of each word in the text.\n",
    "\n",
    "For static word embeddings (such as those provided by Word2Vec, GloVe, or FastText), the centroid is computed by taking the mean of the embedding vectors corresponding to each word in the document. This centroid effectively summarizes the document’s content.\n",
    "\n",
    "#### Required Conditions:\n",
    "- **Availability of Pre-trained Word Embeddings**: You must have access to pre-trained static word embeddings (like GloVe or Word2Vec), allowing each word in the document to map to a vector.\n",
    "- **Comprehensive Word Coverage**: The embeddings must cover the majority of the words in the text to ensure that the centroid accurately represents the document. Missing embeddings for many words can distort the final representation.\n",
    "- **Preprocessing**: Text preprocessing, such as removing unnecessary punctuation or stopwords, ensures that only meaningful words contribute to the centroid.\n",
    "- **Dimensional Consistency**: All word vectors should be of the same dimensionality to allow for proper averaging.\n",
    "\n",
    "#### Advantages of Static Word Embeddings for TRC:\n",
    "1. **Ease of Use**: Static embeddings are relatively easy to compute, and calculating a centroid by averaging vectors is computationally efficient.\n",
    "2. **Speed**: Pre-trained embeddings allow for rapid implementation without needing to train embeddings from scratch.\n",
    "3. **Simplicity in Interpretation**: Since static embeddings are fixed, the centroid can be interpreted as the average meaning of the document's words.\n",
    "\n",
    "#### Disadvantages of Static Word Embeddings for TRC:\n",
    "1. **Context Insensitivity**: Static embeddings do not account for word context, so the same word is always represented by the same vector, which can lead to inaccuracies, especially for words with multiple meanings.\n",
    "2. **Loss of Word Order**: Averaging embeddings disregards word order, meaning important syntactic information is lost.\n",
    "3. **Lack of Up-to-Date Representations**: Static embeddings may not capture newer word usages or domain-specific meanings, limiting their effectiveness.\n",
    "4. **Out-of-Vocabulary Words**: Words that lack pre-trained embeddings are ignored, potentially distorting the centroid.\n",
    "\n",
    "#### Suitable Application Areas:\n",
    "1. **Document Classification**: Using the centroid to represent a document can facilitate its classification based on semantic content.\n",
    "2. **Information Retrieval**: Similarity between document centroids can be useful for retrieving related documents.\n",
    "3. **Summarization**: Centroids can help summarize text content for applications like document or topic summarization.\n",
    "4. **Recommendation Systems**: Centroids can represent documents, articles, or other entities for similarity-based recommendations.\n",
    "\n",
    "### Step 4: My Opinion of ChatGPT's Answer\n",
    "ChatGPT’s response is **accurate**, **concise**, and **well-organized**. It provides a solid explanation of how TRC can be implemented using static word embeddings and discusses the necessary conditions, advantages, disadvantages, and potential application areas.\n",
    "\n",
    "#### Evaluation of ChatGPT's Answer:\n",
    "- **Correctness**: The explanation is precise, clearly describing how TRC can be computed by averaging word embeddings and aligning with current knowledge on static embeddings.\n",
    "- **Coherence**: The response follows a logical structure and covers all aspects in a sequential, coherent manner.\n",
    "- **Comprehensive**: The response addresses all key points—implementation, necessary conditions, pros and cons, and use cases—without leaving out critical information.\n",
    "- **Clarity**: The explanation is easy to follow, using simple language to convey even technical concepts, making it accessible for a broad audience.\n",
    "\n",
    "In conclusion, ChatGPT’s answer is well-structured and offers a comprehensive overview of how TRCs can be implemented using static word embeddings, including their advantages, limitations, and application areas. This explanation can be utilized as a reference or further discussion in a Jupyter notebook or related work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14739a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asahaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

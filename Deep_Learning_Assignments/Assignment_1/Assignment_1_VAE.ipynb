{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 544.576416\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 300.107025\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 290.486725\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 270.903595\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 269.208923\n",
      "====> Epoch: 1 Average loss: 284.5368\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 287.907013\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 270.614655\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 264.772766\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 269.174164\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 268.074310\n",
      "====> Epoch: 2 Average loss: 269.4005\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 273.892334\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 254.424042\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 264.370911\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 262.571930\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 270.489929\n",
      "====> Epoch: 3 Average loss: 266.4905\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 259.826752\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 254.407288\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 266.714691\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 261.919342\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 262.936981\n",
      "====> Epoch: 4 Average loss: 264.6746\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 268.016113\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 264.564636\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 256.936127\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 256.254608\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 251.462204\n",
      "====> Epoch: 5 Average loss: 263.5057\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 270.973816\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 255.749054\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 256.145233\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 275.210602\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 261.798706\n",
      "====> Epoch: 6 Average loss: 262.6984\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 255.162048\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 259.657379\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 276.590637\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 264.987946\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 255.255951\n",
      "====> Epoch: 7 Average loss: 262.0534\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 260.391083\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 265.738770\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 248.648514\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 268.626190\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 264.998230\n",
      "====> Epoch: 8 Average loss: 261.5813\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 250.435669\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 253.797272\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 255.311111\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 255.868484\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 266.445160\n",
      "====> Epoch: 9 Average loss: 261.1659\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 261.619385\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 256.958130\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 268.456696\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 245.120804\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 267.020599\n",
      "====> Epoch: 10 Average loss: 260.7662\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Reference: https://github.com/pytorch/examples/blob/master/vae/main.py, \n",
    "           https://github.com/hwalsuklee/tensorflow-mnist-VAE\n",
    "'''\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "LOG_INTERVAL = 100\n",
    "Z_DIM = 2\n",
    "LEARNING_RATE = 1e-3\n",
    "PRR = True\n",
    "Z1_RANGE = 2\n",
    "Z2_RANGE = 2\n",
    "Z1_INTERVAL = 0.2\n",
    "Z2_INTERVAL = 0.2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "train_data = datasets.FashionMNIST('./data', train=True, download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# pin memory provides improved transfer speed\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# --- defines the model and the optimizer --- #\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 521)\n",
    "        self.fc21 = nn.Linear(512, 2)  # fc21 for mean of Z\n",
    "        self.fc22 = nn.Linear(512, 2)  # fc22 for log variance of Z\n",
    "        self.fc3 = nn.Linear(2, 512)\n",
    "        self.fc4 = nn.Linear(512, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        mu = self.fc21(h1)\n",
    "        # I guess the reason for using logvar instead of std or var is that\n",
    "        # the output of fc22 can be negative value (std and var should be positive)\n",
    "        logvar = self.fc22(h1)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.rand_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch size, 1, 28,28] -> x: [batch size, 784]\n",
    "        x = x.view(-1, 784)\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "# --- defines the loss function --- #\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = 0.5 * torch.sum(mu.pow(2) + logvar.exp() - logvar - 1)\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "# --- train and test --- #\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        # data: [batch size, 1, 28, 28]\n",
    "        # label: [batch size] -> we don't use\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        recon_data, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_data, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        cur_loss = loss.item()\n",
    "        train_loss += cur_loss\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100.*batch_idx / len(train_loader),\n",
    "                cur_loss/len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)\n",
    "    ))\n",
    "\n",
    "\n",
    "# def test(epoch):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (data, label) in enumerate(test_loader):\n",
    "#             data = data.to(device)\n",
    "#             recon_data, mu, logvar = model(data)\n",
    "#             cur_loss = loss_function(recon_data, data, mu, logvar).item()\n",
    "#             test_loss += cur_loss\n",
    "#             if batch_idx == 0:\n",
    "#                 # saves 8 samples of the first batch as an image file to compare input images and reconstructed images\n",
    "#                 num_samples = min(BATCH_SIZE, 8)\n",
    "#                 comparison = torch.cat(\n",
    "#                     [data[:num_samples], recon_data.view(BATCH_SIZE, 1, 28, 28)[:num_samples]]).cpu()\n",
    "#                 save_generated_img(\n",
    "#                     comparison, 'reconstruction', epoch, num_samples)\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "# --- etc. funtions --- #\n",
    "def save_generated_img(image, name, epoch, nrow=8):\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        save_path = 'results/'+name+'_'+str(epoch)+'.png'\n",
    "        save_image(image, save_path, nrow=nrow)\n",
    "\n",
    "\n",
    "def sample_from_model(epoch):\n",
    "    with torch.no_grad():\n",
    "        # p(z) = N(0,I), this distribution is used when calculating KLD. So we can sample z from N(0,I)\n",
    "        sample = torch.randn(64, Z_DIM).to(device)\n",
    "        sample = model.decode(sample).cpu().view(64, 1, 28, 28)\n",
    "        save_generated_img(sample, 'sample', epoch)\n",
    "\n",
    "\n",
    "def plot_along_axis(epoch):\n",
    "    z1 = torch.arange(-Z1_RANGE, Z1_RANGE, Z1_INTERVAL).to(device)\n",
    "    z2 = torch.arange(-Z2_RANGE, Z2_RANGE, Z2_INTERVAL).to(device)\n",
    "    num_z1 = z1.shape[0]\n",
    "    num_z2 = z2.shape[0]\n",
    "    num_z = num_z1 * num_z2\n",
    "\n",
    "    sample = torch.zeros(num_z, 2).to(device)\n",
    "\n",
    "    for i in range(num_z1):\n",
    "        for j in range(num_z2):\n",
    "            idx = i * num_z2 + j\n",
    "            sample[idx][0] = z1[i]\n",
    "            sample[idx][1] = z2[j]\n",
    "\n",
    "    sample = model.decode(sample).cpu().view(num_z, 1, 28, 28)\n",
    "    save_generated_img(sample, 'plot_along_z1_and_z2_axis', epoch, num_z1)\n",
    "\n",
    "\n",
    "# --- main function --- #\n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(epoch)\n",
    "        # test(epoch)\n",
    "        sample_from_model(epoch)\n",
    "\n",
    "        if PRR:\n",
    "            plot_along_axis(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asahaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
